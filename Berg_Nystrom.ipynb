{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Berg_Nystrom.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "pLIjLuVzCOBW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arnauldnzegha/deep2pde_Berg_Nystrom/blob/master/Berg_Nystrom.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "waOAIWCx01Ql",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Implementation of Berg&Nystrom 2019 paper\n",
        "\n",
        "Paper link in Journal of Computational Physics: https://www.sciencedirect.com/science/article/pii/S0021999119300944\n",
        "\n",
        "Arxiv link: https://arxiv.org/abs/1808.10788\n",
        "\n",
        "There are some differences between the two papers (like the NN architecture used).\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "SJ57tszE1tN_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Implementation of the interpolated version\n"
      ]
    },
    {
      "metadata": {
        "id": "_s1MmDNEHt6n",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras import backend as K \n",
        "from keras.models import Model\n",
        "import math as M\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.optimizers import SGD,Adadelta\n",
        "from keras.layers import Dense, Input\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import scipy.io\n",
        "from keras.regularizers import l1\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from random import shuffle\n",
        "import time;"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9pj7pvCyJx7L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading data to compute Burgers PDE\n",
        "\n",
        "*** burgers_sine.mat*** : https://drive.google.com/file/d/1NOYWXhdm6i3zyU5nbcteS617lCDKyc7P/view?usp=sharing\n",
        "\n",
        "Download the file on your local drive and then execute the following code to upload the data on colab.\n",
        "The file contains a compiled matrix of data (what is the structure ?)"
      ]
    },
    {
      "metadata": {
        "id": "6lzUppF8JcFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import zipfile, os\n",
        "BURGERS_DATA_FILE_ID='1NOYWXhdm6i3zyU5nbcteS617lCDKyc7P'\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "dataFile = drive.CreateFile({'id': BURGERS_DATA_FILE_ID})\n",
        "dataFile.GetContentFile('burgers_sine.mat')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q6gCxO-tFy0F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "the **getBurgersData( test  )** function retrieves the data from the **burgers_solution.txt** file and puts it in an array [x_values,  time_values] and an array [U_value].\n",
        "These datas in *** burgers_sine.mat file***  are generated by a solution of the burgers equation.\n",
        "\n",
        "With $\\alpha =\\frac{1}{\\pi} *10^{-2}$"
      ]
    },
    {
      "metadata": {
        "id": "6HvXVf2L-6qB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "files.upload()\n",
        "def get_burgers_data_2(test=0.07,mix=1):\n",
        "\tu_sol=[]\n",
        "\tf = open(\"burgers_solution.txt\", \"r\")\n",
        "\tfor line in f:\n",
        "\t\telts=line.split()\n",
        "\t\tu_sol.extend(elts)\n",
        "\tnb_x_t=100\n",
        "\tmin_x = -1.0\n",
        "\tmax_x = +1.0\n",
        "\tvx = np.linspace ( min_x, max_x, nb_x_t )\n",
        "\tu_sol=np.float32(u_sol).reshape(-1,1)\n",
        "\tmin_t = 0.0\n",
        "\tmax_t = 3.0 / np.pi\n",
        "\tvt = np.linspace ( min_t, max_t, nb_x_t )\n",
        "\tX, T =np.zeros([nb_x_t*nb_x_t]), np.zeros([nb_x_t*nb_x_t])\n",
        "\tX, T =np.zeros([100*100]), np.zeros([100*100])\n",
        "\tfor i in range(0,100):\n",
        "\t\tfor j in range(0, 100):\n",
        "\t\t\tX[100*i+j],T[100*i+j]=vx[i], vt[j]\n",
        "\tx_data=[[X[i],T[i]] for i in range(0,nb_x_t**2)]\n",
        "\tx_data=np.array(x_data).reshape(-1,2)\n",
        "\tn_train = int(len(u_sol)*(1-test))\n",
        "\tif(mix==1): x_data, u_sol= mix_data(x_data, u_sol)\n",
        "\tX_train, Y_train = x_data[:n_train],  u_sol[:n_train]\n",
        "\tX_test, Y_test = x_data[n_train:], u_sol[n_train:]\n",
        "\treturn np.array(X_train), np.array(Y_train), np.array(X_test), np.array(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q5uF_HZk-2i3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_square_data(test=0.07,mix=1):\n",
        "    x=np.array([i for i in range(0,10000)])/10000\n",
        "    t=np.array([i for i in range(0,10000)])/10000\n",
        "    x,s=mix_data(x,x)\n",
        "    t,s=mix_data(t,t)\n",
        "    X=[[x[i],t[i]] for i in range(0,9999)]\n",
        "    X_sol_star = np.hstack((t,x))\n",
        "    #print(X)\n",
        "    u_sol_star=[x[0]**2 + x[1]**2 for x in X]\n",
        "    #if(mix==1): X_sol_star, u_sol_star= mix_data(X_sol_star, u_sol_star)\n",
        "    n_train = int(len(u_sol_star)*(1-test))\n",
        "    X_train, Y_train = X[:n_train],  u_sol_star[:n_train]\n",
        "    X_test, Y_test = X[n_train:], u_sol_star[n_train:]\n",
        "    return  np.array(X_train), np.array(Y_train), np.array(X_test), np.array(Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LGjGSRZxN5eq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The mixData shuffle xs in a random order. ys ?"
      ]
    },
    {
      "metadata": {
        "id": "TRfAboKa-_ka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def mix_data(xs,ys):\n",
        "    xys=[]\n",
        "    for i in range(0,len(xs)-1):\n",
        "        xys.append((xs[i],ys[i]))\n",
        "    shuffle(xys)\n",
        "    x2,y2=[],[]\n",
        "    for (x,y) in xys:\n",
        "        x2.append(x)\n",
        "        y2.append(y)\n",
        "    return (np.array(x2), np.array(y2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JFV1VoCVPuBN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implementation of the first MLP\n",
        "\n",
        "The first model is a neural network (a MLP) with **5 hidden** layers and **10 units by hidden** layers. The activation is hyperbolic tangent.\n",
        "L1 regulation term is used during training"
      ]
    },
    {
      "metadata": {
        "id": "SZFccSvz-DvG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def berg_nystrom_model1():\n",
        "    L1_PENALTY_TERM=0.01\n",
        "    l1_Reg = l1(L1_PENALTY_TERM)\n",
        "    input_data = Input(shape=(2,))\n",
        "    hidden1 = Dense(10, activation='tanh', name='l1' ,kernel_regularizer=l1_Reg)(input_data)\n",
        "    hidden2 = Dense(10, activation='tanh', name='l2' ,kernel_regularizer=l1_Reg)(hidden1)\n",
        "    hidden3 = Dense(10, activation='tanh', name='l3' ,kernel_regularizer=l1_Reg)(hidden2)\n",
        "    hidden4 = Dense(10, activation='tanh', name='l4' ,kernel_regularizer=l1_Reg)(hidden3)\n",
        "    hidden5 = Dense(10, activation='tanh', name='l5' ,kernel_regularizer=l1_Reg)(hidden4)\n",
        "    output = Dense(1, activation='linear', name='l6' ,kernel_regularizer=l1_Reg)(hidden5)\n",
        "    model = Model(input_data, output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JNg1mm_D-9-Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def berg_nystrom_model2(nb_class=1):\n",
        "    input_data = Input(shape=(3,))\n",
        "    hidden1 = Dense(2, activation='tanh', name='l1')(input_data)\n",
        "    hidden2 = Dense(2, activation='tanh', name='l2')(hidden1)\n",
        "    output = Dense(nb_class, activation='linear', name='sort')(hidden2)\n",
        "    model = Model(input_data, output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U7mTURPQZJ4O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def berg_nystrom_model2_linear(nb_class=1):\n",
        "    input_data = Input(shape=(3,))\n",
        "    output = Dense(nb_class, activation='linear', name='sort')(input_data)\n",
        "    model = Model(input_data, output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2SH_8iN2axOi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def berg_nystrom_model2_linear_k2(nb_class=1):\n",
        "    input_data = Input(shape=(3,))\n",
        "    output = Dense(nb_class, activation='linear', name='sort')(input_data)\n",
        "    model = Model(input_data, output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l-MGaAM2aQYX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**dataTrainModelEDP(X,U)** \n",
        "\n",
        "take a liste(** [x_value , time_val]** and** [u_value],** )  \n",
        "\n",
        "and return a liste   **([U_value, x derivative of U, second order x derivative of U]**  and **[time derivative of U named Ut]**)"
      ]
    },
    {
      "metadata": {
        "id": "hRVMOZ5J-036",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_to_train_model2(X,U):\n",
        "    X_der=np.zeros(len(X))\n",
        "    T_der=np.zeros(len(X))\n",
        "    X_der2=np.zeros(len(X))\n",
        "    X_train=np.zeros([len(X),3])\n",
        "    for i in range(0, len(X)):\n",
        "        layer_outs = get_layer_outputs(X[i])\n",
        "        X_train[i][0]=U[i]\n",
        "        X_train[i][1]=partiel_derivative(-1,0,X[i],layer_outs,tanh_deriv)\n",
        "        X_train[i][2]=partiel_derivative(-1,1,X[i],layer_outs,tanh_deriv)\n",
        "        X_der2[i]=partiel_derivative(-1,0,X[i],layer_outs, tanh_deriv2)\n",
        "        #print(str(X[i][1])+\"##--##\"+str(X_train[i][2]))\n",
        "    return X_train, X_der2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vAgTHEeFGSnZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_to_train_model2_2(modelX,X,U):\n",
        "    X_der=np.zeros(len(X))\n",
        "    T_der=np.zeros(len(X))\n",
        "    X_der2=np.zeros(len(X))\n",
        "    X_train=np.zeros([len(X),3])\n",
        "    for i in range(0, len(X)):\n",
        "        X_train[i][0]=U[i]\n",
        "        X_train[i][1]=partiel_derivative_2(modelX,0,X[i])\n",
        "        X_train[i][2]=partiel_derivative_2(modelX,0,X[i])\n",
        "        X_der2[i]=(partiel_derivative_2(modelX,0,X[i]+0.00001)-partiel_derivative_2(modelX,0,X[i]))/0.00001\n",
        "        #print(str(X[i][1])+\"##--##\"+str(X_train[i][2]))\n",
        "    return X_train, X_der2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AtPIQWdqcSPZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This code returne in a list the output of each layer after a prediction."
      ]
    },
    {
      "metadata": {
        "id": "eUGtjfsz-yw0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_layer_outputs(test_data):\n",
        "    test_data=test_data.reshape(1,2,)\n",
        "    ar=np.float32(test_data)\n",
        "    test_data2=[[ar]]\n",
        "    outputs = [layer.output for layer in model.layers[1:]]\n",
        "    functors = [K.function([model.input, K.learning_phase()], [out]) for out in outputs] \n",
        "    layer_outs = [func([test_data, 1.]) for func in functors]\n",
        "    return test_data2+layer_outs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irXbkHUDcyPN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**tanh_deriv** return the derivative of tanh. $$th' = (1-th^2)$$\n",
        "\n",
        "\n",
        "**tanh_deriv2** return the second order derivative  $$th' ' =  -2(th - th^3)$$\n"
      ]
    },
    {
      "metadata": {
        "id": "64hOhGDD-tO4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def tanh_deriv(x):\n",
        "    return(1-(M.tanh(x))**2)\n",
        "\n",
        "def tanh_deriv2 (x):\n",
        "    return(-2*(M.tanh(x) -(M.tanh(x))**3))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jwVKAbTB-lpQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partiel_derivative(layer, n_i, inputX, layer_outs, fct_deriv):\n",
        "    nb_l=len(model.layers)\n",
        "    if((layer)>(-1*nb_l)):\n",
        "        ln=len(model.layers[layer].get_weights()[0][0])\n",
        "        if((layer-1)>(-1*nb_l)):\n",
        "            inp=len(model.layers[layer-1].get_weights()[0][0])\n",
        "        else:\n",
        "            inp=len(inputX)\n",
        "        Lpartial=np.zeros(ln)\n",
        "        LpartialN=partiel_derivative(layer-1 ,n_i, inputX,layer_outs, fct_deriv)\n",
        "        chaine=0\n",
        "        for n in range(0,ln):\n",
        "            act=model.layers[layer].get_weights()[1][n]\n",
        "            chaine=0\n",
        "            for i in range(0,inp):\n",
        "                W=model.layers[layer].get_weights()[0][i][n]\n",
        "                act+=W*layer_outs[layer-1][0][0][i]\n",
        "                chaine+=W*LpartialN[i]\n",
        "            if (layer==-1):\n",
        "                Lpartial[n]=chaine\n",
        "            else:\n",
        "                Lpartial[n] = fct_deriv(act)*chaine\n",
        "        return Lpartial\n",
        "    else:\n",
        "        Lpartial=np.zeros(len(inputX))\n",
        "        Lpartial[n_i]=1\n",
        "        return Lpartial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lwmcq9X5bQAw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partiel_derivative_skl(layer, n_i, inputX, layer_outs, fct_deriv):\n",
        "    nb_l=len(Berg_Nystrom_skl_model_1.coefs_)\n",
        "    if((layer)>(-1*nb_l)):\n",
        "        ln=len(Berg_Nystrom_skl_model_1.coefs_[layer][:,0])\n",
        "        if((layer-1)>(-1*nb_l)):\n",
        "            inp=len(model.layers[layer-1].get_weights()[0])\n",
        "        else:\n",
        "            inp=len(inputX)\n",
        "        Lpartial=np.zeros(ln)\n",
        "        LpartialN=partiel_derivative(layer-1 ,n_i, inputX,layer_outs, fct_deriv)\n",
        "        chaine=0\n",
        "        for n in range(0,ln):\n",
        "            act=model.layers[layer].get_weights()[1][:,n]\n",
        "            chaine=0\n",
        "            for i in range(0,inp):\n",
        "                W=model.layers[layer].get_weights()[0][i][:,n]\n",
        "                act+=W*layer_outs[layer-1][0][0][i]\n",
        "                chaine+=W*LpartialN[i]\n",
        "            if (layer==-1):\n",
        "                Lpartial[n]=chaine\n",
        "            else:\n",
        "                Lpartial[n] = fct_deriv(act)*chaine\n",
        "        return Lpartial\n",
        "    else:\n",
        "        Lpartial=np.zeros(len(inputX))\n",
        "        Lpartial[n_i]=1\n",
        "        return Lpartial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a9r1P20PZk_o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def partiel_derivative_2(modelX,n_i, inputX):\n",
        "  inputX1=np.array([inputX])\n",
        "  inputX1[n_i]=inputX1[n_i]+0.000001\n",
        "  y1, y2= modelX.predict(inputX.reshape(1,2,)), modelX.predict(inputX1.reshape(1,2,))\n",
        "  derv= (y2[0]-y1[0])/0.000001\n",
        "  return derv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pLIjLuVzCOBW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using Keras"
      ]
    },
    {
      "metadata": {
        "id": "WsIxo6LhVWwT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training phase 1 (1rst model) with SDG and the mean squared error.\n"
      ]
    },
    {
      "metadata": {
        "id": "LN8HyawD-6yi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test= get_burgers_data_2()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EfNOoF5B-Zno",
        "colab_type": "code",
        "outputId": "e241d61e-7e42-4b42-a4bc-792830d55ae3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "model = berg_nystrom_model1()\n",
        "LEARNING_RATE,MOMENTUM,DECAY=0.01,0.9,1e-6\n",
        "sgd = SGD(lr=LEARNING_RATE, decay=DECAY, momentum=MOMENTUM, nesterov=True)\n",
        "#optim_results = tfp.optimizer.lbfgs_minimize( quadratic, initial_position=start, num_correction_pairs=10, tolerance=1e-8)\n",
        "model.compile(loss='mean_squared_error', optimizer=sgd,  metrics=['accuracy'])\n",
        "\n",
        "t= time.time()\n",
        "hist=model.fit(X_train, Y_train, validation_split=0.15, batch_size=50, epochs=1000, verbose=0)\n",
        "print(\"training time for  model (100 iterations) :\"+str(time.time()-t))\n",
        "print(\"cross validation mean error : \"+str(hist.history[\"val_loss\"][-1]))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time for  model (100 iterations) :644.4429681301117\n",
            "cross validation mean error : 0.17890616957645689\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QeoOsAckXBbv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Gradients computation. 1rst order and 2nd order"
      ]
    },
    {
      "metadata": {
        "id": "B8eFXveG6CKi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.initialize_all_variables())\n",
        "grad_func = tf.gradients(model.output[:,0], model.input)\n",
        "grad_func_second = tf.gradients(grad_func, model.input)\n",
        "Uxt = sess.run(grad_func, feed_dict={model.input: X_train.reshape((-1, X_test[1].size))})[0]\n",
        "Uxxtt = sess.run(grad_func_second, feed_dict={model.input: X_train.reshape((-1, X_test[1].size))})[0]\n",
        "Ux_xx_train=[[X_train[i][0],Uxt[i][0],Uxxtt[i][0]] for i in range(0,len(Uxt))]\n",
        "Ut_train=[[Uxt[i][1]] for i in range(0,len(Uxt))]\n",
        "Ux_xx_train, Ut_train=np.array(Ux_xx_train), np.array(Ut_train)\n",
        "print(Ut_train)\n",
        "print(\"-------------\")\n",
        "print(X_train)\n",
        "print(\"-------------\")\n",
        "print(Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UxpKcGCEXunD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The training phase1 (2nd model) with SDG and the mean squared error."
      ]
    },
    {
      "metadata": {
        "id": "RIc9-6sfE3QT",
        "colab_type": "code",
        "outputId": "370c78e9-346d-4f0d-df0e-e73bdd3356e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "model2 = berg_nystrom_model2()\n",
        "model2.compile(loss='mean_squared_error', optimizer=sgd,  metrics=['accuracy'])\n",
        "t= time.time()\n",
        "#X_train, Y_train, X_test, Y_test= get_burgers_data_2()\n",
        "#X_train2, Y_train2=X_train[:300, :], Y_train[:300,]\n",
        "#Uxx, Ut=data_to_train_model2(X_train2, Y_train2)\n",
        "t2= time.time()\n",
        "print(\"Partial derivatives computation time (50 derivative) :\"+str(t2-t))\n",
        "hist=model2.fit(Ux_xx_train, Ut_train, validation_split=0.1, batch_size=500, epochs=2000, verbose=0)\n",
        "print(\"training time for  model (100 iterations) :\"+str(time.time()-t2))\n",
        "#print(\"cross validation mean error : \"+str(hist.history[\"val_loss\"][-1]))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Partial derivatives computation time (50 derivative) :1.811981201171875e-05\n",
            "training time for  model (100 iterations) :101.31483769416809\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vktVe8N-ZZ2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83a8bf5c-5115-44ea-9a1c-b72b42887915"
      },
      "cell_type": "code",
      "source": [
        "model2_linear = berg_nystrom_model2_linear()\n",
        "model2_linear.compile(loss='mean_squared_error', optimizer=sgd,  metrics=['accuracy'])\n",
        "t= time.time()\n",
        "hist=model2_linear.fit(Ux_xx_train, Ut_train, validation_split=0.1, batch_size=50, epochs=2000, verbose=0)\n",
        "print(\"training time for  model (100 iterations) :\"+str(time.time()-t))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training time for  model (100 iterations) :791.6421501636505\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "784IdtAdC2J4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test of pr√©diction of the model trained using keras"
      ]
    },
    {
      "metadata": {
        "id": "uTpgRwbJ0fNb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "I just the prediction to see if it is close to u_val.\n"
      ]
    },
    {
      "metadata": {
        "id": "_LcMh1IbXyQd",
        "colab_type": "code",
        "outputId": "fe750ef4-4f39-4560-fd3d-b4277a255b9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "#X_train, Y_train, X_test, Y_test= get_burgers_data_2()\n",
        "y_pred = model.predict(X_test)\n",
        "print(\"Prediction of 1st Model && U(x,t)\")\n",
        "for i in range(0,5):\n",
        "  print(str(y_pred[i])+\" && \" +str(Y_test[i]))\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "y_pred2 = model2.predict(Ux_xx_train[:10, :])\n",
        "print(\"Prediction of 2nd Model && U_t,\")\n",
        "for i in range(0,5):\n",
        "  print(str(y_pred2[i])+\" && \" +str(Ut_train[i]))\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "y_pred3 = model2_linear.predict(Ux_xx_train[:10, :])\n",
        "print(\"Prediction of 2nd Model linear && U_t,\")\n",
        "for i in range(0,5):\n",
        "  print(str(y_pred3[i])+\" && \" +str(Ut_train[i]))"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of 1st Model && U(x,t)\n",
            "[0.108721] && [0.198996]\n",
            "[0.4887313] && [0.569988]\n",
            "[0.3917535] && [0.309611]\n",
            "[-0.5242994] && [-0.62857]\n",
            "[-0.6488479] && [-0.483511]\n",
            " \n",
            "Prediction of 2nd Model && U_t,\n",
            "[0.5777677] && [0.56916785]\n",
            "[0.38966668] && [0.388359]\n",
            "[0.8864609] && [0.9259329]\n",
            "[1.015756] && [0.9934623]\n",
            "[1.1128973] && [1.1266155]\n",
            " \n",
            "Prediction of 2nd Model linear && U_t,\n",
            "[0.49723503] && [0.56916785]\n",
            "[0.40814295] && [0.388359]\n",
            "[0.7996401] && [0.9259329]\n",
            "[0.9136801] && [0.9934623]\n",
            "[1.1327826] && [1.1266155]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "u_HJIeLPYCm_",
        "colab_type": "code",
        "outputId": "31ec91b0-c65d-49fd-b034-fc7f9d017910",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(0,3):\n",
        "  print(model2.layers[-3+i].get_weights()[0][0])"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.3913877 0.5314901]\n",
            "[-0.5014231   0.94413483]\n",
            "[0.11260688]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k5NP-dAKKyMf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Using SKlearn\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "e5G6b1AlSFdT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "create models 1 and 2"
      ]
    },
    {
      "metadata": {
        "id": "-rq9FXhFSPhN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "Berg_Nystrom_skl_model_1 = MLPRegressor(solver='lbfgs',activation='tanh', alpha=1e-5, hidden_layer_sizes=(10, 10, 10, 10, 10), random_state=1, max_iter=1000)\n",
        "\n",
        "Berg_Nystrom_skl_model_2 = MLPRegressor(solver='lbfgs',activation='tanh', alpha=1e-5, hidden_layer_sizes=(50,50,50,50), random_state=1, max_iter=1000)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZPrG2nuiXBui",
        "colab_type": "code",
        "outputId": "811be7d6-c650-45ed-f727-3cb74798c225",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test= get_burgers_data_2()\n",
        "for i in range(0, 100):\n",
        "  Berg_Nystrom_skl_model_1.fit(X_train, Y_train)\n",
        "#print(Berg_Nystrom_skl_model_2.coefs_[0][:,0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:1316: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ghh-WGP7f9TE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Uxx, Ut=data_to_train_model2_2(Berg_Nystrom_skl_model_1,X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bz_EqMybhpfz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(0, 100):\n",
        "  Berg_Nystrom_skl_model_2.fit(Uxx, Ut)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7-jpqYTbh65B",
        "colab_type": "code",
        "outputId": "9c8cd406-4358-48bb-e0ea-1df480db8187",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "cell_type": "code",
      "source": [
        "y_p = Berg_Nystrom_skl_model_2.predict(Uxx[:9])\n",
        "print(y_p)\n",
        "print(Ut[:9])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 14.50681752  14.50681752 -31.12226425 -31.12226425 -31.12226425\n",
            " -31.12226425  14.50681752 -31.12226425 -31.12226425]\n",
            "[ 1.78846937e+01  1.41314516e+01 -1.61326508e+00  3.65245612e+00\n",
            " -2.05651052e+00 -3.87427126e+03  5.08941778e+00 -8.53154214e+00\n",
            " -4.77951012e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_KX3Zt5fW9_W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Uelq2zrfgU4v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train the model using Sklearn"
      ]
    },
    {
      "metadata": {
        "id": "nrzdFG84KIZM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test= get_burgers_data_2()\n",
        "model1_SKL = MLPRegressor(solver='lbfgs',activation='tanh', alpha=1e-5, hidden_layer_sizes=(10, 10, 10, 10, 10), random_state=1, max_iter=1000)\n",
        "for i in range(0, 100):\n",
        "  model1_SKL.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qnivpTi6DVP5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Test the model trained using sklearn"
      ]
    },
    {
      "metadata": {
        "id": "jVY10_WmFm0l",
        "colab_type": "code",
        "outputId": "627a4780-b84a-4e8b-a49a-5bd7bba5794b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, Y_train, X_test, Y_test= get_burgers_data_2(mix=0)\n",
        "U=Y_test\n",
        "#y_pred = model1_SKL.predict(X_train[1:])\n",
        "print(\"Prediction of 1st Model && U(x,t) trained with sklearn\")\n",
        "for i in range(0,7):\n",
        "  y_p = model1_SKL.predict(np.array(X_test[i]).reshape(1,2,))\n",
        "  y=partiel_derivativeX(model1_SKL,0,X_test[i])\n",
        "  print(str(X_test[i][0])+\" &\"+str(X_test[i][1])+\"    ==  \"+str(y_p[0])+\" && \" +str(U[i])+\" dev \"+str(y))\n",
        "y_p = model1_SKL.predict(X_test)\n",
        "for i in range(0,5):\n",
        "  print(str(y_p[i])+\" && \" +str(U[i]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction of 1st Model && U(x,t) trained with sklearn\n",
            "[-0.39609123]||[-0.396089]\n",
            "0.8787878787878789 &0.0    ==  -0.3960912336584304 && [-0.371662] dev 2.2341963947791754\n",
            "[-0.38933704]||[-0.38933484]\n",
            "0.8787878787878789 &0.009645754126781536    ==  -0.3893370412623195 && [-0.361368] dev 2.2010053586929423\n",
            "[-0.38269401]||[-0.38269185]\n",
            "0.8787878787878789 &0.019291508253563072    ==  -0.3826940130400681 && [-0.351595] dev 2.167813585141065\n",
            "[-0.37616202]||[-0.37615989]\n",
            "0.8787878787878789 &0.02893726238034461    ==  -0.3761620235779398 && [-0.34231] dev 2.1346658243270866\n",
            "[-0.36974081]||[-0.36973871]\n",
            "0.8787878787878789 &0.038583016507126144    ==  -0.36974081195334935 && [-0.33348] dev 2.1016039318810797\n",
            "[-0.36342999]||[-0.36342792]\n",
            "0.8787878787878789 &0.04822877063390768    ==  -0.36342999098599416 && [-0.325074] dev 2.0686669304215144\n",
            "[-0.35722906]||[-0.35722702]\n",
            "0.8787878787878789 &0.05787452476068922    ==  -0.35722905627899215 && [-0.317064] dev 2.035891079221752\n",
            "-0.3960912336584305 && [-0.371662]\n",
            "-0.38933704126231966 && [-0.361368]\n",
            "-0.38269401304006845 && [-0.351595]\n",
            "-0.3761620235779397 && [-0.34231]\n",
            "-0.36974081195334924 && [-0.33348]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EanNPcq63LLF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Visualisation"
      ]
    },
    {
      "metadata": {
        "id": "Y-y9vVAwMlLD",
        "colab_type": "code",
        "outputId": "0b793382-8651-4dad-84cc-bef71cd9fc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "cell_type": "code",
      "source": [
        "X_test3=X_test[:2000,:1].reshape(-1)\n",
        "y_pred2=y_p[:2000].reshape(-1)\n",
        "plt.plot(y_pred2, X_test3, 'r')\n",
        "\n",
        "\n",
        "y_pred2=U[:2000].reshape(-1)\n",
        "plt.plot(y_pred2, X_test3,'g')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4e2b75ac8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "Wlgs4Epeddr7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_activations(clf, test_input):\n",
        "        test_input=test_input.reshape(1,2,)\n",
        "        hidden_layer_sizes = clf.hidden_layer_sizes\n",
        "        if not hasattr(hidden_layer_sizes, \"__iter__\"):\n",
        "            hidden_layer_sizes = [hidden_layer_sizes]\n",
        "        hidden_layer_sizes = list(hidden_layer_sizes)\n",
        "        layer_units = [test_input.shape[1]] + hidden_layer_sizes + \\\n",
        "            [clf.n_outputs_]\n",
        "        activations = [test_input]\n",
        "        for i in range(clf.n_layers_ - 1):\n",
        "            activations.append(np.empty((test_input.shape[0],\n",
        "                                         layer_units[i + 1])))\n",
        "        clf._forward_pass(activations)\n",
        "        activations=[x[0] for x in activations]\n",
        "        return activations"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X_L2hMCWYSi7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}